{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c6b2707",
   "metadata": {},
   "source": [
    "***IMPORTS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57b0ef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import pickle\n",
    "import plotly as plt\n",
    "\n",
    "#Processing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "#Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5c348e",
   "metadata": {},
   "source": [
    "***DATA CLEANING***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3a3a4",
   "metadata": {},
   "source": [
    "**Analyse what the data represents and which variables have enough data to work with**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d299164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load_raw_data\n",
    "rawdata =  pd.read_csv('C:/Users/Admiral Akhbar/Desktop/Markit/ds_assessment_data_2008_2016.csv', na_values=[\"inf\",\"-inf\",\"\",\" \"], keep_default_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5459af10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set output options to explore data more easily\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 20)\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0923e4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Check out the data to see if it loaded ok\n",
    "rawdata.head(10)\n",
    "rawdata.shape\n",
    "rawdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908a18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial missing value check\n",
    "missing_values = pd.DataFrame(rawdata.isnull().sum(),columns=['NA_count'])\n",
    "missing_values['var'] = missing_values.index\n",
    "missing_values.sort_values(by='NA_count',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d10de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's spend some time exploring the summary stats\n",
    "summary_stats = pd.DataFrame(rawdata.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf48799",
   "metadata": {},
   "source": [
    "From the summary stats we can see blah blah...\n",
    "From the summary stats it's clear we have some infinite values in the raw data here\n",
    "I have chosen to fix this by setting them as NA in the data read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21719b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's drop variables with a lot of missing values that are also highly correlated with variables we keep\n",
    "# These vars are probably not worth imputing/fixing\n",
    "# An alternative approach here would be to conisder dropping firms with lots of missing values across variables\n",
    "# However, without knowing much about the firms in the data I believe this can bias the data and model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dbcd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have 856 year-company observations in the dataset\n",
    "#Let's first consider throwing away variables with less than say 2/3rds of year-company observations\n",
    "#In this case I set the threshold at 350 obs\n",
    "vars_to_drop = missing_values[missing_values['NA_count']>=350]['var']\n",
    "\n",
    "len(vars_to_drop) #This gives us 62 candidates to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865eb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's set up the data as a panel dataset with id and year\n",
    "rawdata.set_index(['id','fiscal_year_end_year'], inplace=True, verify_integrity=True)\n",
    "\n",
    "#Let's get rid of calender year, we won't need it now as year is in the index\n",
    "rawdata.drop(columns='calendar_end', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I find the highly correlated variables for the ones I want to throw out \n",
    "#I then decide if the variables I want to drop have sensible financial proxies left in the dataset\n",
    "#There's probably a package that does this properly for panel data in Python but I struggled to find one, so did it by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5003d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up vars that we don't want to drop to check correlations \n",
    "vars_to_keep = rawdata.columns.to_series()\n",
    "vars_to_keep = vars_to_keep[~vars_to_keep.isin(vars_to_drop)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c6ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set_up a full correlation matrix\n",
    "cor_matrix_full = rawdata.corr()\n",
    "\n",
    "#Set up Data frame for check\n",
    "cor_matrix_check = pd.DataFrame(index=vars_to_drop)\n",
    "cor_matrix_drop = cor_matrix_full.loc[vars_to_drop,vars_to_keep]\n",
    "\n",
    "#Bring out index values for easy intrective sorting\n",
    "cor_matrix_check[\"var_to_drop\"] = cor_matrix_check.index.values\n",
    "\n",
    "#Find max corr across vars\n",
    "cor_matrix_check['Max_corr']=cor_matrix_drop.max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find vars that have maxx corr\n",
    "#Get variables to keep names\n",
    "cor_matrix_drop = pd.melt(cor_matrix_drop, ignore_index=False, value_name='corr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9058f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave only variables where correlation matches max cor\n",
    "cor_matrix_check = pd.merge(cor_matrix_drop,cor_matrix_check,how='inner',left_index=True,right_index=True)\n",
    "cor_matrix_check = cor_matrix_check.loc[cor_matrix_check['corr']==cor_matrix_check['Max_corr'],:]\n",
    "print(cor_matrix_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on inspecting cor_matrix_check I decided not to drop the following variables:\n",
    "# FCF\n",
    "# as they/it have/has no sensible (from a financial analysis point of view) proxies left in the dataset\n",
    "vars_to_drop = vars_to_drop.drop(['FCF'])\n",
    "vars_to_keep = pd.concat([vars_to_keep,pd.Series(['FCF'])],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013167cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's drop the other vars and check missing values again\n",
    "rawdata.drop(columns=vars_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5a634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second missing value check to check it worked correctly\n",
    "missing_values = pd.DataFrame(rawdata.isnull().sum(),columns=['NA_count'])\n",
    "missing_values.sort_values(by='NA_count',ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898dc6d",
   "metadata": {},
   "source": [
    "**Fix Missing Values and decide Divident Cut threshold**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6128d7",
   "metadata": {},
   "source": [
    "Becasue we're working with Balance sheet / P&L / Cash Flow Statement items we can't just backfill/pad missing values\n",
    "\n",
    "I would try to impute missing values using MICE (Multiple Imputation by Chained Equations) and some sensible financial relationships\n",
    "\n",
    "However, this will likely be industry-specific (and GAAP/IFRS specific) and with no industry variable here, no units (currency, million/billion) for many of the other variables, I'll need to do something simple and easy to understand like  K-Nearest Neighbours (KNN)\n",
    "\n",
    "We are using all the data here, which is a bit of a cheat (I am doing this before the test/train split\n",
    "and so test data info will \"leak\" in the train dataset)\n",
    "\n",
    "However, it shouldn't matter when it comes to evaluating performance on the 2017 hold-out set and imputing the missing values during the test/train split with KNN can result in extra varience in the model performance which is difficult to control\n",
    "Given that we have a lot imputing to do, I have chosen to do it pre test-train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83a8558",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First off, let's fix the dividend return variable\n",
    "#It's ok to pad with 0s here as missing values are due to time cut-off\n",
    "clean_data = rawdata.copy()\n",
    "clean_data['Dividend_returns'] = clean_data['Dividend_returns'].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70756e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also remove the Dividents variable, since we're predicting a cut and can't use it in this scenario\n",
    "clean_data.drop(columns='Dividend', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f250f4bc",
   "metadata": {},
   "source": [
    "Now let's encode a target variable, with a given threshold\n",
    "\n",
    "The threshold will depend on how I want to use the model, presumably to trade ahead of cut announcements \n",
    "\n",
    "In practice I would want to set a threshold based on how significant the market reaction to the announcement of the cut is,\n",
    "for example share price performance in a X-day period after a cut of a given size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518b4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For now let's make a sensible guess\n",
    "threshold = float(-0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082dc596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gen cut var\n",
    "clean_data['Div_Cut']=0\n",
    "clean_data.loc[clean_data['Dividend_returns'] <= threshold,'Div_Cut']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52384fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how many firms had a cut at that threshold\n",
    "check = clean_data[['Div_Cut']].groupby(axis='index', level=[0]).mean()\n",
    "check.sort_values(by='Div_Cut', axis=0, ascending=False, inplace=True)\n",
    "print(len(check[check['Div_Cut']>0]),\" out of \",len(check),\" firms or \",\n",
    "      round(len(check[check['Div_Cut']>0])/len(check),2)*100, \"% of all firms had a cut at the \",\n",
    "      threshold, \" threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see a rough distribution (across years) of cuts by firm\n",
    "#check.plot().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444a4b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's see how cuts vary across years at this threshold\n",
    "check = clean_data[['Div_Cut']].groupby(axis='index', level=[1]).sum()\n",
    "check.sort_values(by='Div_Cut', axis=0, ascending=False)\n",
    "#check.plot().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4f29c5",
   "metadata": {},
   "source": [
    "Ok this threshold seems reasonable enough to proceed with\n",
    "\n",
    "Now I will use K-Nearest Neighbours imputation to fix missing values \n",
    "\n",
    "As far as I can see, this should work off the data.frame index and so should take into account patterns in both firm and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think it's good practiceto make all the key parameters for the imputer explicit here\n",
    "imputer = KNNImputer(missing_values=np.nan, n_neighbors=2, weights='uniform', metric='nan_euclidean', copy=True, add_indicator=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdef862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute\n",
    "imputed_data = pd.DataFrame(imputer.fit_transform(clean_data))\n",
    "#add back var names\n",
    "imputed_data.columns = clean_data.columns\n",
    "#add back index\n",
    "imputed_data.index = clean_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75a6877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's drop divident returns as a column as this will not be known in the prediction year\n",
    "imputed_data.drop('Dividend_returns', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's add back the firm id as a variable\n",
    "imputed_data[\"firm_id\"] = imputed_data.index.get_level_values(0)\n",
    "#and then remove it from the index\n",
    "imputed_data.index = imputed_data.index.droplevel(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bba4a6e",
   "metadata": {},
   "source": [
    "**Test / Train Split for model selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7bd90d",
   "metadata": {},
   "source": [
    "One way to do this is to backtest rolling windows for a few years of data for all firms. The problem is this will leaves me with an unballanced panel by firm as not all firms have data for all years since 2008\n",
    "\n",
    "A second way to do this is to hold out data for some of the firms each time, but use all years\n",
    "    \n",
    "A third option is to use all data (2008-2015) for all firms to train and test on 2016, given that is the year closest to the hold-out year (2017)\n",
    "\n",
    "I have chosen the third option because I expect the same firms to be included in the hold-out set and I can reduce overfitting by cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e348c965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to test the models on all firms for 2016\n",
    "# Because the data is already sorted by year and firm_id (as this was the index)\n",
    "# We could take every 6th observation, if all firms had existed in at the start of the data in 2008\n",
    "# Let's check\n",
    "print(\"Avg years per firm are \", str(len(imputed_data) / len(imputed_data[\"firm_id\"].unique())))\n",
    "\n",
    "# Sadly not all firms have existed since 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf36c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Therefore I must take the 2016 observation for each firm for the X_test set\n",
    "# and leave the rest for the X_train set which leaves us with a slighly unequal panel by firm\n",
    "\n",
    "X_test = imputed_data.loc[2016,imputed_data.columns != 'Div_Cut']\n",
    "y_test = imputed_data.loc[2016,'Div_Cut']\n",
    "X_train = imputed_data.loc[range(2008,2016),imputed_data.columns != 'Div_Cut']\n",
    "y_train = imputed_data.loc[range(2008,2016),'Div_Cut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2723d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that nothing went wrong\n",
    "print('Check that X and y are equal')\n",
    "print(len(X_test)==len(y_test),\"for X and y test\")\n",
    "print(len(X_train)==len(y_train),\"for X and y train\")\n",
    "\n",
    "print('Check I split the entire set')\n",
    "print(len(X_test)+len(X_train)==len(imputed_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b369bbe",
   "metadata": {},
   "source": [
    "**Data transformation for modelling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1eb7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now I transform my training data\n",
    "\n",
    "#Encode firm_id as dummy var\n",
    "Firm_Encoder = OneHotEncoder(categories='auto', drop=None, sparse=True, handle_unknown='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41284dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale features that are not finanial_health_score or firm_id by centering around the mean\n",
    "Values_Encoder = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f6dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select features to center\n",
    "Values_features = ['ASSETS', 'BPS', 'CAPEX', 'CFPS', 'CF_FIN',\n",
    "       'CF_INV', 'CF_OP', 'DEPR_AMORT', 'EBIT', 'EBITDA', 'EPS', 'EPS_GAAP',\n",
    "       'EPS_NONGAAP', 'FCF', 'G_A_EXP', 'INT_EXP', 'NDT', 'NET', 'NETBG',\n",
    "       'PTI', 'SALES', 'SH_EQUITY', 'CAPEX_returns', 'CF_OP_returns',\n",
    "       'EBIT_returns', 'EBITDA_returns', 'EPS_GAAP_returns', 'NDT_returns',\n",
    "       'NET_returns', 'NETBG_returns', 'PTI_returns', 'SH_EQUITY_returns',\n",
    "       'CFPS_returns', 'EPS_returns', 'SALES_returns', 'payout_ratio',\n",
    "       'earnings_cover', 'cashflow_cover', 'debt_factor', 'profitability']\n",
    "\n",
    "#Check we have the right features\n",
    "X_train.columns[~X_train.columns.isin(Values_features)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f26d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can apply the transformations to the data\n",
    "#Let's set_up a transformer object\n",
    "\n",
    "data_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('firm', Firm_Encoder,['firm_id']),\n",
    "        ('Values_Enc_1',Values_Encoder, Values_features)\n",
    "    ],remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a818bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit to the data and transform it\n",
    "data_transformer.fit(X_train)\n",
    "X_train_trans = data_transformer.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f39513",
   "metadata": {},
   "source": [
    "***MODELLING***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e275b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'll first try out a few reliable models to understand how they perform and which one shows the most promise\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
